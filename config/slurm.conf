# slurm.conf file generated by configurator.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ControlMachine=c04u01
#ControlAddr=
BackupController=c04u12
#BackupAddr=
# 
AuthType=auth/none
CacheGroups=0
#CheckpointType=checkpoint/none 
CryptoType=crypto/munge
#DisableRootJobs=NO 
#EnforcePartLimits=NO 
#Epilog=
#EpilogSlurmctld= 
#FirstJobId=1 
#MaxJobId=999999 
GresTypes=gpu
#GroupUpdateForce=0 
#GroupUpdateTime=600 
JobCheckpointDir=/var/lib/slurm-llnl/checkpoint 
#JobCredentialPrivateKey=
#JobCredentialPublicCertificate=
#JobFileAppend=0 
#JobRequeue=1 
#JobSubmitPlugins=1 
#KillOnBadExit=0 
#LaunchType=launch/slurm 
#Licenses=foo*4,bar 
#MailProg=/usr/bin/mail 
#MaxJobCount=5000 
#MaxStepCount=40000 
#MaxTasksPerNode=128 
MpiDefault=none
#MpiParams=ports=#-# 
#PluginDir= 
#PlugStackConfig= 
#PrivateData=jobs 
ProctrackType=proctrack/pgid
#Prolog=
#PrologSlurmctld= 
#PropagatePrioProcess=0 
#PropagateResourceLimits= 
#PropagateResourceLimitsExcept= 
#RebootProgram= 
ReturnToService=1
#SallocDefaultCommand= 
SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/lib/slurm-llnl/slurmd
SlurmUser=slurm
#SlurmdUser=root 
#SrunEpilog=
#SrunProlog=
#StateSaveLocation=/var/lib/slurm-llnl/slurmctld
# shared NFS across the slowpokes, assumes that slurm user IDs are the same
StateSaveLocation=/nrs/turaga/slurm/slurmctld
SwitchType=switch/none
#TaskEpilog=

# whether to pin tasks to the CPUs they requested

# no pinning
#TaskPlugin=task/none

# pinning using affinity
# (doesn't seem to work, don't see error messages either)
#TaskPlugin=task/affinity
#TaskPluginParam=Cpusets

# pinning using cgroup
# (this one works; for docker, --parent-cgroup has to be set)
TaskPlugin=task/cgroup
#TaskPluginParam=

#TaskProlog=
#TopologyPlugin=topology/tree 
#TmpFS=/tmp 
#TrackWCKey=no 
#TreeWidth= 
#UnkillableStepProgram= 
#UsePAM=0 
# 
# 
# TIMERS 
#BatchStartTimeout=10 
#CompleteWait=0 
#EpilogMsgTime=2000 
#GetEnvTimeout=2 
#HealthCheckInterval=0 
#HealthCheckProgram= 
InactiveLimit=0
KillWait=30
#MessageTimeout=10 
#ResvOverRun=0 
MinJobAge=300
#OverTimeLimit=0 
SlurmctldTimeout=120
SlurmdTimeout=300
#UnkillableStepTimeout=60 
#VSizeFactor=0 
# Wait for 10 seconds to kill pending tasks in a job, as soon as one task
# failed or srun was ^Ced. In run_docker, we wait for 5s before we kill, so
# that should be enough.
Waittime=10
# 
# 
# SCHEDULING 
#DefMemPerCPU=0 

# only if set to 0, the actual resources (except CPUs) of a node are considered for scheduling
# if set to 1, this configuration file will be used, and a node set to DRAIN or DOWN if it has less
FastSchedule=0

#MaxMemPerCPU=0 
#SchedulerRootFilter=1 
#SchedulerTimeSlice=30 
SchedulerType=sched/backfill
SchedulerPort=7321
SelectType=select/cons_res
SelectTypeParameters=CR_CPU_Memory
# 
# 
# JOB PRIORITY 
#PriorityFlags= 
#PriorityType=priority/basic 
#PriorityDecayHalfLife= 
#PriorityCalcPeriod= 
#PriorityFavorSmall= 
#PriorityMaxAge= 
#PriorityUsageResetPeriod= 
#PriorityWeightAge= 
#PriorityWeightFairshare= 
#PriorityWeightJobSize= 
#PriorityWeightPartition= 
#PriorityWeightQOS= 
# 
# 
# LOGGING AND ACCOUNTING 
#AccountingStorageEnforce=0 
#AccountingStorageHost=
#AccountingStorageLoc=
#AccountingStoragePass=
#AccountingStoragePort=
AccountingStorageType=accounting_storage/none
#AccountingStorageUser=
AccountingStoreJobComment=YES
ClusterName=cluster
#DebugFlags= 
#JobCompHost=
#JobCompLoc=
#JobCompPass=
#JobCompPort=
JobCompType=jobcomp/none
#JobCompUser=
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/none
SlurmctldDebug=3
SlurmctldLogFile=/var/log/slurm-llnl/slurmctld.log
SlurmdDebug=3
SlurmdLogFile=/var/log/slurm-llnl/slurmd.log
#SlurmSchedLogFile= 
#SlurmSchedLogLevel= 
# 
# 
# POWER SAVE SUPPORT FOR IDLE NODES (optional) 
#SuspendProgram= 
#ResumeProgram= 
#SuspendTimeout= 
#ResumeTimeout= 
#ResumeRate= 
#SuspendExcNodes= 
#SuspendExcParts= 
#SuspendRate= 
#SuspendTime= 
# 
# 
# COMPUTE NODES 
NodeName=c04u01 CPUs=64 Sockets=2 CoresPerSocket=16 ThreadsPerCore=2 Gres=gpu:8 State=IDLE
NodeName=c04u07 CPUs=80 Sockets=2 CoresPerSocket=20 ThreadsPerCore=2 Gres=gpu:8 State=IDLE
NodeName=c04u12 CPUs=80 Sockets=2 CoresPerSocket=20 ThreadsPerCore=2 Gres=gpu:8 State=IDLE
NodeName=c04u17 CPUs=80 Sockets=2 CoresPerSocket=20 ThreadsPerCore=2 Gres=gpu:8 State=IDLE
PartitionName=slowpokes Nodes=c04u[01,07,12,17] Default=YES MaxTime=INFINITE State=UP
